# 消息丢失
首先说明一个概念：message delivery semantic 也就是消息传递语义，简单说就是消息传递过程中消息传递的保证性。主要分为三种：
* at most once：最多一次。消息可能丢失也可能被处理，但最多只会被处理一次。
* at least once：至少一次。消息不会丢失，但可能被处理多次。可能重复，不会丢失。
* exactly once：精确传递一次。消息被处理且只会被处理一次。不丢失不重复就一次。

理想情况下肯定是希望系统的消息传递是严格exactly once，也就是保证不丢失、只会被处理一次，但是很难做到。

Kafka有三次消息传递的过程：
1. 消息产生。生产者发消息给Kafka Broker
2. 消息保存。Kafka Broker 消息同步和持久化
3. 消息消费。Kafka Broker 将消息传递给消费者并进行消费 

在这三步中每一步都有可能会丢失消息。

## 一、消息丢失情况
### 1) 消息产生过程消息丢失
为了避免消息产生过程消息丢失，在Kafka Broker收到消息后可进行一个ACK确认。
![kafka-message-produce.png](../images/kafka-message-produce.png)
Kafka通过配置 `request.required.acks` 属性来确认消息的生产：
* 0表示不进行消息接收是否成功的确认。不能保证消息是否发送成功，生成环境基本不会用，可能丢失消息。
* 1表示当Leader接收成功时确认。如果这时Leader挂了，一个未同步到这条消息的Follower被选举为Leader，可能丢失消息。
* -1或者all表示Leader和Follower(实际上是ISR)都接收成功时确认（实际上Leader + `min.insync.replicas`确认就可以了）。可以最大限度保证消息不丢失，但是吞吐量低。
> 难道不加一个半数Leader/Follower成功就ACK吗？

#### request.required.acks=0/1造成消息丢失
原因如上所述。

#### 发送时使用buffer造成消息丢失
为了提升效率，减少IO，producer在发送数据时可以将多个请求进行合并后发送，被合并的请求咋发送一线缓存在本地buffer中（buffer满了会丢弃消息或block阻塞）。
producer可以将请求打包成“块”或者按照时间间隔，将buffer中的数据发出。通过buffer我们可以将生产者改造为异步的方式，而这可以提升我们的发送效率。

但Producer崩掉了或者是被强行关掉了，buffer里的数据就会丢失。

#### 网络原因造成消息丢失
消息产生过程中由于网络原因失败了，但不确定是上图的步骤2还是步骤6，因此这时Producer并不知道成功与否，如果不重新发送消息，则可能消息丢失；如果重新发送，则可能生成重复消息。

这种情况是无解的，只能接受可能的消息丢失（at most once）或重复消息（at least once）。

### 2) 消息保存过程消息丢失
场景一：Leader Broker 宕机了，触发选举过程，集群选举了一个落后 Leader 太多的 Broker 作为 Leader，那么落后的那些消息就会丢失了。

场景二：Kafka 为了提升性能，使用页缓存机制，将消息写入页缓存而非直接持久化至磁盘，采用了异步批量刷盘机制，也就是说，按照一定的消息量和时间间隔去刷盘，刷盘的动作由操作系统来调度的，如果刷盘之前，Broker 宕机了，重启后在页缓存的这部分消息则会丢失。


### 3) 消息消费过程消息丢失
消费者通过pull模式主动的去 kafka 集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader分区去拉取。
![kafka-message-consume.png](../images/kafka-message-consume.png)
消费者消费的进度通过offset保存在kafka集群的__consumer_offsets这个topic中。

消费消息的时候主要分为两个操作：
- 标识消息已被消费，commit offset坐标
- 业务方处理消息

这两个操作无法做到原子性，所以也是会导致消息丢失或者重复消费的。

场景一：先commit再处理消息。如果在处理消息的时候异常了，但是offset 已经提交了，造成消息丢失。

场景二：先处理消息再commit。如果在commit之前发生异常，下次还会消费到该消息，造成重复消费。

> 这里不增加一个ACK机制吗？  
> 如果某条消息本身异常，一直消费失败，按场景二，是会一直卡在那儿吗？

### 总结
在生产环境中严格做到exactly once其实是难的，同时也会牺牲效率和吞吐量，最佳实践是业务侧做好补偿机制，万一出现消息丢失可以兜底。
如果业务侧能做到消息的消费幂等，是可以接受消息重复的（at least once）。

## 二、at least once
对于重要的消息可以尽量做到 `at least once`，并在业务上做一些防重处理。
### 1) Producer端
- 不要使用 `producer.send(msg)`，而要使用 `producer.send(msg, callback)`。带有回调通知的 send 方法可以针对发送失败的消息进行重试处理。
- 设置 `acks = all` 及 `min.insync.replicas`（消息生产确认：需要Leader + `min.insync.replicas`个Replicas确认，默认值为1）。注意需要 `replication.factor > min.insync.replicas`
- 设置 `retries` 及 `retry.backoff.ms` ，重试次数及间隔（这个期间不会阻塞消息的Produce，因而可能改变消息的顺序，但可以设置 `max.in.flight.requests.per.connection=1` 解决）。
- 不要使用 buffer
### 2) Broker端
- 为Partition多设置几个副本 `replication.factor`（不要设置为1）
### 3) Consumer端
- 确保消息消费完成再提交。最好把它设置成 enable.auto.commit = false，并采用手动提交位移的方式。