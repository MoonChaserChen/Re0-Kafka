# 草稿
## 核心的API:

* The Producer API 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。
* The Consumer API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。
* The Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
* The Connector API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

## Leader 如果宕机但 ISR 却为空该如何处理
可以通过配置 `unclean.leader.election`

true：允许 OSR 成为 Leader，但是 OSR 的消息较为滞后，可能会出现消息不一致的问题
false：会一直等待旧 leader 恢复正常，降低了可用性

## 如何判断一个 Broker 是否还有效
- Broker必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个结点的连接。
- 如果Broker是个Follower，它必须能及时同步Leader的写操作，延时不能太久。

## Kafka 日志存储的Message是什么格式
afka一个Message由固定长度的header和一个变长的消息体body组成。将Message存储在日志时采用不同于Producer发送的消息格式。每个日志文件都是一个log entries（日志项）序列：

* 每一个log entry包含一个四字节整型数（Message长度，值为1+4+N）。
* 1个字节的magic，magic表示本次发布Kafka服务程序协议版本号。
* 4个字节的CRC32值，CRC32用于校验Message。
* 最终是N个字节的消息数据。每条消息都有一个当前Partition下唯一的64位offset。

## Kafka 中如何进行主从同步
kafka 通过配置 producer.type 来确定是异步还是同步，默认是同步